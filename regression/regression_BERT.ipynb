{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контекст\n",
    "\n",
    "- модель регрессии (схожесть двух предложений)\n",
    "- модель distilbert\n",
    "- структура input_ids: индексы токенов из словаря первого sentence SEP индексы токенов из словаря второго sentence\n",
    "- SEP - токен конца + токен разделения двух sentence\n",
    "- метрики: MSE, RMSE, MAE, Pirson, Spierman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import DistilBertConfig,\\\n",
    "                         DistilBertTokenizerFast,\\\n",
    "                         DistilBertForSequenceClassification,\\\n",
    "                         TrainingArguments,\\\n",
    "                         Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import pearsonr,\\\n",
    "                        spearmanr\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Скачиваем модель и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased',num_labels=1)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased', max_length = 512)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6</td>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.2</td>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                     sentence_1  \\\n",
       "0    2.5                    A girl is styling her hair.   \n",
       "1    3.6       A group of men play soccer on the beach.   \n",
       "2    5.0  One woman is measuring another woman's ankle.   \n",
       "3    4.2                A man is cutting up a cucumber.   \n",
       "4    1.5                       A man is playing a harp.   \n",
       "\n",
       "                                         sentence_2  \n",
       "0                      A girl is brushing her hair.  \n",
       "1  A group of boys are playing soccer on the beach.  \n",
       "2           A woman measures another woman's ankle.  \n",
       "3                      A man is slicing a cucumber.  \n",
       "4                      A man is playing a keyboard.  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spisok = []\n",
    "with open('sts-test.csv', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        to_frame = line.split('\\t')\n",
    "        if len(to_frame) == 7:\n",
    "            spisok.append(to_frame[-3:])\n",
    "\n",
    "\n",
    "data = pd.DataFrame(spisok, columns = ['label', 'sentence_1', 'sentence_2'])\n",
    "data['label'] = data['label'].astype('Float32')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-val-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 219 219\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    data,\n",
    "    train_size = int(len(data)*0.6),\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "test, val = train_test_split(\n",
    "    test,\n",
    "    test_size = 0.5,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  1037,\n",
       "  2711,\n",
       "  2003,\n",
       "  16018,\n",
       "  27130,\n",
       "  1012,\n",
       "  102,\n",
       "  1037,\n",
       "  4937,\n",
       "  2003,\n",
       "  17033,\n",
       "  1037,\n",
       "  5835,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': 0.0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "\n",
    "        tokenized_data = tokenizer(\n",
    "            row['sentence_1'],\n",
    "            row['sentence_2'],\n",
    "            truncation = True,\n",
    "            padding = True,\n",
    "            return_attention_mask = True\n",
    "            )\n",
    "        \n",
    "        label = row['label']\n",
    "        \n",
    "        return {\n",
    "            'input_ids': tokenized_data['input_ids'],\n",
    "            'attention_mask': tokenized_data['attention_mask'],\n",
    "            'labels': label\n",
    "        }\n",
    "    \n",
    "\n",
    "RegressionDataset(train)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "        output_dir='training/model_points',\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_strategy='steps',\n",
    "        logging_dir='training/logs',\n",
    "        logging_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps = 500,\n",
    "        fp16=True,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to = 'wandb'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "\n",
    "    preds = np.squeeze(pred.predictions)\n",
    "\n",
    "    return {\"MSE\": ((preds - pred.label_ids)**2).mean().item(),\n",
    "            \"RMSE\": (np.sqrt (( (preds - pred.label_ids)** 2).mean())).item(),\n",
    "            \"MAE\": (np.abs(preds - pred.label_ids)).mean().item(),\n",
    "            \"Pearson\" : pearsonr(preds,pred.label_ids)[0],\n",
    "            \"Spearman's Rank\":spearmanr(preds,pred.label_ids)[0]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oudel\\anaconda3\\envs\\newenv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1898a306b5446c498710bab011c674e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4086, 'grad_norm': 22.844818115234375, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1330b56709624188834044daea50504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7941495180130005, 'eval_MSE': 0.7941495180130005, 'eval_RMSE': 0.8911506533622742, 'eval_MAE': 0.7150071263313293, 'eval_Pearson': 0.8217444159643199, \"eval_Spearman's Rank\": 0.7844024366328554, 'eval_runtime': 0.1396, 'eval_samples_per_second': 1568.556, 'eval_steps_per_second': 28.649, 'epoch': 2.38}\n",
      "{'loss': 0.5632, 'grad_norm': 28.229604721069336, 'learning_rate': 4.8e-05, 'epoch': 4.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf409d22aeb422c87a2f7b1936a6dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.826815128326416, 'eval_MSE': 0.826815128326416, 'eval_RMSE': 0.9092937707901001, 'eval_MAE': 0.7466901540756226, 'eval_Pearson': 0.8332740408136717, \"eval_Spearman's Rank\": 0.8077182829360665, 'eval_runtime': 0.1448, 'eval_samples_per_second': 1512.748, 'eval_steps_per_second': 27.63, 'epoch': 4.76}\n",
      "{'loss': 0.3328, 'grad_norm': 7.859753608703613, 'learning_rate': 2.909090909090909e-05, 'epoch': 7.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecaa1daf61b47afa7c1b4e35ee70f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5644059777259827, 'eval_MSE': 0.5644059777259827, 'eval_RMSE': 0.7512695789337158, 'eval_MAE': 0.6069604754447937, 'eval_Pearson': 0.8552356505469322, \"eval_Spearman's Rank\": 0.8280123801555602, 'eval_runtime': 0.1528, 'eval_samples_per_second': 1432.901, 'eval_steps_per_second': 26.172, 'epoch': 7.14}\n",
      "{'loss': 0.1599, 'grad_norm': 7.392002582550049, 'learning_rate': 6.363636363636363e-06, 'epoch': 9.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e79770dc5b49ae8d0219464eb6ad7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.581851065158844, 'eval_MSE': 0.5818511247634888, 'eval_RMSE': 0.7627916932106018, 'eval_MAE': 0.5855435132980347, 'eval_Pearson': 0.8491636079985622, \"eval_Spearman's Rank\": 0.8249211146562015, 'eval_runtime': 0.1509, 'eval_samples_per_second': 1451.578, 'eval_steps_per_second': 26.513, 'epoch': 9.52}\n",
      "{'train_runtime': 12.1191, 'train_samples_per_second': 542.12, 'train_steps_per_second': 17.328, 'train_loss': 0.5920652423586165, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=210, training_loss=0.5920652423586165, metrics={'train_runtime': 12.1191, 'train_samples_per_second': 542.12, 'train_steps_per_second': 17.328, 'train_loss': 0.5920652423586165, 'epoch': 10.0})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = RegressionDataset(train),\n",
    "        eval_dataset = RegressionDataset(val),\n",
    "        compute_metrics = compute_metrics,\n",
    "        tokenizer = tokenizer\n",
    "\n",
    " )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет метрик для каждого сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4d3d3c94274bfeadebf6406bd5bb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d5812f78484943bf2e444603377bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d77a54c5c94956bc61c1d99d10cd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_MSE</th>\n",
       "      <th>eval_RMSE</th>\n",
       "      <th>eval_MAE</th>\n",
       "      <th>eval_Pearson</th>\n",
       "      <th>eval_Spearman's Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.063369</td>\n",
       "      <td>0.063369</td>\n",
       "      <td>0.251733</td>\n",
       "      <td>0.200834</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>0.985437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.588180</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>0.827138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.659939</td>\n",
       "      <td>0.659939</td>\n",
       "      <td>0.812366</td>\n",
       "      <td>0.616345</td>\n",
       "      <td>0.850734</td>\n",
       "      <td>0.831835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eval_loss  eval_MSE  eval_RMSE  eval_MAE  eval_Pearson  \\\n",
       "train   0.063369  0.063369   0.251733  0.200834      0.986426   \n",
       "val     0.592400  0.592400   0.769675  0.588180      0.849793   \n",
       "test    0.659939  0.659939   0.812366  0.616345      0.850734   \n",
       "\n",
       "       eval_Spearman's Rank  \n",
       "train              0.985437  \n",
       "val                0.827138  \n",
       "test               0.831835  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=[trainer.evaluate(eval_dataset=data) for data in [RegressionDataset(train), RegressionDataset(val), RegressionDataset(test)]]\n",
    "pd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка на двух схожих предложениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8192057609558105"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1, s2=\"A plane is taking off.\", \"An air plane is taking off.\"\n",
    "\n",
    "encoding = tokenizer(\n",
    "    s1,s2,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "model = model.cpu()\n",
    "outputs = model(input_ids, attention_mask = attention_mask)\n",
    "outputs.logits.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка на двух разных предложениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3200218379497528"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1, s2=\"The men are playing soccer.\", \"A man is riding a motorcycle.\"\n",
    "\n",
    "encoding = tokenizer(\n",
    "    s1, s2,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "outputs.logits.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
